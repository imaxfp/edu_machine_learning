{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n",
      "1.0\n",
      "0.5000000025\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "print(sigmoid(1))\n",
    "print(sigmoid(99999))\n",
    "print(sigmoid(0.00000001))\n",
    "print(sigmoid(5184))\n",
    "\n",
    "x = np.linspace(-10, 10, 100)\n",
    "z = list(map(lambda x: sigmoid(x), x))\n",
    "\n",
    "plt.plot(x, z)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Sigmoid(X)\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision boundary\n",
    "\n",
    "Linear Regression can be used for classification problems\n",
    "if h0(x) >= 0.5, predict 'yes'\n",
    "if h0(x) < 0.5, predict 'no'\n",
    "However, this method doesn't work well because classification is not actually a linear function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear Decision Boundary\n",
    "<br>\n",
    "\n",
    "<img src=\"../img/log_reg/lenear_decision_boundry.png\" width=\"500\"/>\n",
    "\n",
    "Theta parameters \"θ1, θ2, θ3\" should be selected for the better result of decision boundary line.\n",
    "\n",
    "Non-linear Decision Boundary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making predictions\n",
    "Using our knowledge of sigmoid functions and decision boundaries, we can now write a prediction function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The loss function (also known as a cost function)\n",
    "We can’t (or at least shouldn’t) use the same cost function MSE (L2) as we did for linear regression.\n",
    "Instead of Mean Squared Error, we use a cost function called ***Cross-Entropy*** also known as ***Log Loss.***\n",
    "Cross-entropy loss can be divided into two separate cost functions: one for y=1 and one for y=0.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/log_reg/cost_fun_2_log_reg.png\" width=\"500\"/>\n",
    "\n",
    "overfitting_problems.png\n",
    "<br>\n",
    "<img src=\"../img/log_reg/cost_fun_3_log_reg.png\" width=\"500\"/>\n",
    "<br>\n",
    "<img src=\"../img/log_reg/log_reg_cost_fun.png\" width=\"500\"/>\n",
    "\n",
    "Above functions compressed into one. The main aim is minimization 'J' of theta.\n",
    "<img src=\"../img/log_reg/fun_compressed_into_one.png\" width=\"500\"/>\n",
    "<br>\n",
    "Vectorized cost function\n",
    "<img src=\"../img/log_reg/vectorized_cost_function.png\" width=\"500\"/>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    '''\n",
    "    Returns 1D array of probabilities\n",
    "    that the class label == 1\n",
    "    '''\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def cost_function(features, labels, weights):\n",
    "    '''\n",
    "    Using Mean Absolute Error\n",
    "\n",
    "    Features:(100,3)\n",
    "    Labels: (100,1)\n",
    "    Weights:(3,1)\n",
    "    Returns 1D matrix of predictions\n",
    "    Cost = (labels*log(predictions) + (1-labels)*log(1-predictions) ) / len(labels)\n",
    "    '''\n",
    "    observations = len(labels)\n",
    "\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels * np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1 - labels) * np.log(1 - predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gradient descent\n",
    "Optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model.\n",
    "\n",
    "Which leads to an equally beautiful and convenient cost function derivative:\n",
    "\n",
    "C'=x(s(z)-y)\n",
    "\n",
    "1. C' is the derivative of cost with respect to weights\n",
    "2. y is the actual class label (0 or 1)\n",
    "3. s(z) is your model’s prediction\n",
    "4. x is your feature or feature vector.\n",
    "\n",
    "\n",
    "##### Pseudocode\n",
    "Repeat {\n",
    "  1. Calculate gradient average\n",
    "  2. Multiply by learning rate\n",
    "  3. Subtract from weights\n",
    "}\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/log_reg/vectorized_cost_details.png\" width=\"500\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def predict(features, weights):\n",
    "    '''\n",
    "    Returns 1D array of probabilities\n",
    "    that the class label == 1\n",
    "    '''\n",
    "    z = np.dot(features, weights)\n",
    "    return sigmoid(z)\n",
    "\n",
    "\n",
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "\n",
    "    Features:(200, 3)\n",
    "    Labels: (200, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    gradient = np.dot(features.T, predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Put all parts together, provide example\n",
    "To perform a prediction, you use neural network-like notation; you have weights (w), inputs (x) and bias (b)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-8e7be5f2f1bd>:19: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#lr = CustomLogisticRegression()\n",
    "#lr.fit(x_train, y_train, epochs=150)\n",
    "\n",
    "# 0. You start by doing the weight and sigmoid calculation.\n",
    "# 1. Multiply the inputs with the weights and add the bias.\n",
    "# 2. Input these weights into the sigmoid function and get predictions.\n",
    "# 3. Compute the loss by the implemented compute_loss function and the derivative by the compute_gradients function\n",
    "# 4. The loss is not used in the model (only the derivative of the loss is used). but you can monitor the loss to determine when your model cannot learn more, which is how the 150 epochs were chosen for the model.\n",
    "# 5.  Finally, you update the parameters of the model, and then you start the next iteration and continue iterating until you reach 150 iterations.\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "     The loss function (also known as a cost function) is implemented as a vectorized solution exactly like you saw in the explanation section into the formula.\n",
    "     Finding all of the errors by comparing your ground truth y_true to your predictions y_pred\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # binary cross entropy\n",
    "    y_zero_loss = y_true * np.log(y_pred + 1e-9)\n",
    "    y_one_loss = (1 - y_true) * np.log(1 - y_pred + 1e-9)\n",
    "    return -np.mean(y_zero_loss + y_one_loss)\n",
    "\n",
    "\n",
    "def compute_gradients(x, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    You start by finding the difference (how much your model predicted wrong)\n",
    "    and use it to calculate the gradients for the bias by finding the average error.\n",
    "    calculate the gradients, which are what you use to update the model parameters.\n",
    "    :param x:\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #  Start by finding the difference (how much your model predicted wrong)\n",
    "    difference = y_pred - y_true\n",
    "    #  calculate the gradients for the bias by finding the average error.\n",
    "    gradient_bias = np.mean(difference)\n",
    "    #  multiply the difference by the inputs (x).\n",
    "    #  https://numpy.org/doc/stable/reference/generated/numpy.transpose.html\n",
    "    gradients_w = np.matmul(x.transpose(), difference)\n",
    "    #  find the average of each gradient. Row of the matrix\n",
    "    gradients_w_mean = np.array([np.mean(grad) for grad in gradients_w])\n",
    "\n",
    "    return gradients_w_mean, gradient_bias\n",
    "\n",
    "\n",
    "def update_model_parameters(weights, bias, error_w, error_b):\n",
    "    weights = weights - 0.1 * error_w\n",
    "    bias = bias - 0.1 * error_b\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "def fit(x, y, epochs):\n",
    "    x = copy.deepcopy(x).values\n",
    "    y = copy.deepcopy(y).values\n",
    "\n",
    "    weights = np.zeros(x.shape[1])\n",
    "    bias = 0\n",
    "    losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        #  Matrix product of two arrays.\n",
    "        x_dot_weights = np.matmul(weights, x.transpose()) + bias\n",
    "        pred = sigmoid(x_dot_weights)\n",
    "        loss = compute_loss(y, pred)\n",
    "        error_w, error_b = compute_gradients(x, y, pred)\n",
    "        weights, bias = update_model_parameters(weights, bias, error_w, error_b)\n",
    "\n",
    "        pred_to_class = [1 if p > 0.5 else 0 for p in pred]\n",
    "        train_accuracies.append(accuracy_score(y, pred_to_class))\n",
    "        losses.append(loss)\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "def predict(weights, bias, x):\n",
    "    x_dot_weights = np.matmul(x, weights.transpose()) + bias\n",
    "    probabilities = sigmoid(x_dot_weights)\n",
    "    return [1 if p > 0.5 else 0 for p in probabilities]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = pd.read_csv(\"../data/breast_cancer_x_data.csv\")\n",
    "    y = pd.read_csv(\"../data/breast_cancer_y_target_data.csv\")\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    weights, bias = fit(x_train, y_train, 150)\n",
    "    pred = predict(weights, bias, x_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiclass Classification problem:\n",
    "Email -> Hobby, Friends, Work, Family\n",
    "Medical -> not ill, cold, flue\n",
    "\n",
    "Now we will approach the classification of data when we have more than two categories. Instead of y = {0,1} we will expand our definition so that y = {0,1...n}\n",
    "Applying binary logistic regression to each case '{0,1...n}', and then use the hypothesis that returned the highest value as our prediction.\n",
    "<br>\n",
    "<img src=\"../img/log_reg/multiclass_classification.png\" width=\"500\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}