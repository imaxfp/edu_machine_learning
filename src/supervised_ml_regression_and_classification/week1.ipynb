{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Week 1\n",
    "\n",
    "Arthur Samuel. He defined machine learning as the field of study that gives computers\n",
    "the ability to learn without being explicitly programmed.\n",
    "\n",
    "##### Question 1\n",
    "If Arthur Samuel's checkers-playing program had been allowed to play only 10 games\n",
    "(instead of tens of thousands games) against itself, how would this have affected its performance?\n",
    "\n",
    "- Would have made it worse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "##### Supervised learning - Regression\n",
    "Can then take a brand new input x, something it has never seen before, and try to produce the appropriate corresponding output y.\n",
    "\n",
    "<img src=\"../../img/coursera/supervised/ml_supervised_examples.png\" width=\"450\"/>\n",
    "\n",
    "What you've seen in this slide is an example of supervised learning. Because we gave the algorithm a dataset in which the so-called right answer, that is the label or the correct price y is given for every house on the plot.\n",
    "\n",
    "<img src=\"../../img/coursera/supervised/lr/house_price_pred.png\" width=\"300\"/>\n",
    "<br>\n",
    "\n",
    "That's supervised learning, learning input, output, or x to y mappings."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Supervised learning - Classification algorithm\n",
    "\n",
    "So what I say class or category when referring to the output, it means the same thing. So to summarize classification algorithms predict categories. Categories don't have to be numbers. It could be non numeric for example, it can predict whether a picture is that of a cat or a dog. And it can predict if a tumor is benign or malignant. Categories can also be numbers like 0, 1 or 0, 1, 2. But what makes classification different from regression when you're interpreting the numbers is that classification predicts a small finite limited set of possible output categories such as 0, 1 and 2 but not all possible numbers in between like 0.5 or 1.7. In the example of supervised learning that we've been looking at, we had only one input value the size of the tumor.\n",
    "\n",
    "You can also use more than one input value to predict an output, for example AGE ans tumor SIZE. And so given this, how can we predict if this patient's tumor is benign or malignant? Well, given the day said like this, what the learning algorithm might do is find some boundary that separates out the malignant tumors from the benign ones.\n",
    "\n",
    "<img src=\"../../img/coursera/supervised/classification_example.png\" width=\"300\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/supervised_learning_summ.png\" width=\"450\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Unsupervised learning\n",
    "\n",
    "Were given data that isn't associated with any output labels y, say you're given data on patients and their tumor size and the patient's age. But not whether the tumor was benign or malignant, so the dataset looks like this on the right. We're not asked to diagnose whether the tumor is benign or malignant, because we're not given any labels.\n",
    "\n",
    "instead, our job is to find some structure or some pattern or just find something interesting in the data.\n",
    "<br>\n",
    "<img src=\"../../img/coursera/unsupervised/unsupervised.png\" width=\"300\"/>\n",
    "\n",
    "particular type of unsupervised learning, called a clustering algorithm. Because it places the unlabeled data, into different clusters.\n",
    "<img src=\"../../img/coursera/unsupervised/clustering_google_news.png\" width=\"400\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/unsupervised/clustering_dna.png\" width=\"400\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/unsupervised/clustering_people.png\" width=\"400\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/unsupervised/unsupervised_examples.png\" width=\"400\"/>\n",
    "\n",
    "##### Question 2\n",
    "Of the following examples, which would you address using an unsupervised learning algorithm?  (Check all that apply.)\n",
    "\n",
    "- Given a set of news articles found on the web, group them into sets of articles about the same stories.\n",
    "- Given a database of customer data, automatically discover market segments and group customers into different market segments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Practice quiz: Supervised vs unsupervised learning\n",
    "\n",
    "Question 1\n",
    "Which are the two common types of supervised learning? (Choose two)\n",
    "- Classification\n",
    "- Regression\n",
    "\n",
    "Question 2\n",
    "Which of these is a type of unsupervised learning?\n",
    "- Clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Supervised learning - Linear regression model\n",
    "\n",
    "We call this supervised learning because you are first training a model by giving a data that has right answers because you get the model examples of houses with both the size of the house, as well as the price that the model should predict for each house.\n",
    "<img src=\"../../img/coursera/supervised/lr/linear_regression.png\" width=\"400\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/linear_regression_table.png\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "##### x or feature:\n",
    "The dataset that you just saw and that is used to train the model is called a training set.\n",
    "In Machine Learning, the standard notation to denote the input here is lowercase x, and we call this the input variable, is also called a feature or an input feature. For example, for the first house in your training set, x is the size of the house, so x equals 2,104.\n",
    "\n",
    "##### target variable:\n",
    "The standard notation to denote the output variable which you're trying to predict, which is also sometimes called the target variable, is lowercase y.\n",
    "\n",
    "##### m or number of examples:\n",
    "Lowercase m to refer it to the total number of training examples, and so here m is equal to 47.\n",
    "\n",
    "##### superscript ^(n), for instance ^(1):\n",
    "The superscript tells us that this is the ith training example, such as the first, second, or third up to the 47th training example.\n",
    "\n",
    "<img src=\"../../img/coursera/supervised/lr/linear_regression_terminology.png\" width=\"450\"/>\n",
    "\n",
    "What is the math formula we're going to use to compute f?\n",
    "Here's what this function is doing, it's making predictions for the value of y using a streamline function of x. Linear function is relatively simple and easy to work with, let's use a line as a foundation that will eventually help you to get to more complex models that are non-linear. This particular model has a name, it's called linear regression. More specifically, this is linear regression with one variable, where the phrase one variable means that there's a single input variable or feature x, namely the size of the house. Another name for a linear model with one input variable is univariate linear regression, where uni means one in Latin, and where variate means variable. Univariate is just a fancy way of saying one variable.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/linear_regression_model.png\" width=\"500\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/lr_question1.png\" width=\"600\"/>\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/notation.png\" width=\"800\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost function formula\n",
    "The cost function will tell us how well the model is doing so that we can try to get it to do better.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_function_main_formula.png\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "To introduce a little bit more terminology the w and b are called the parameters of the model. In machine learning parameters of the model are the variables you can adjust during training in order to improve the model.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_fun_examples.png\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "A training example like this point here is defined by 'x' superscript i, i'y' superscript i where y is the target. For a given input x^i, the function f also makes a predictive value for 'y' and a value that it predicts to 'y'.\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_fun_squared_err.png\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "When measuring the error, for example i, we'll compute this squared error term. Finally, we want to measure the error across the entire training set. In particular, let's sum up the squared errors like this. We'll sum from i equals 1,2, 3 all the way up to m and remember that m is the number of training examples, which is 47 for this dataset.\n",
    "\n",
    "Notice that if we have more training examples 'm' is larger and your cost function will calculate a bigger number. This is summing over more examples. To build a cost function that doesn't automatically get bigger as the training set size gets larger by convention, **we will compute the average squared error instead of the total squared error and we do that by dividing by 'm' like this.**\n",
    "\n",
    "By convention, the cost function that machine learning people use actually divides by 2 times m. The extra division by 2 is just meant to make some of our later calculations look neater, but the cost function still works whether you include this division by 2 or not. This expression right here is the cost function and we're going to write J of wb to refer to the cost function.\n",
    "\n",
    " **The squared error cost function is by far the most commonly used one for linear regression and for that matter, for all regression problems where it seems to give good results for many applications**\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/question_cost_fun.png\" width=\"500\"/>\n",
    "<br>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost function intuition\n",
    "We'll walk through one example to see how the cost function can be used to find the best parameters for your model.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_function_intuition.png\" width=\"300\"/>\n",
    "<br>\n",
    "\n",
    "You may recall that the cost function is defined as follows, is the squared error cost function. If you substitute fw(X^i) with w times X^i, the cost function looks like this. Where this expression is now w times X^i minus Y^i. For this value of w, it turns out that the error term inside the cost function, this w times X^i minus Y^i is equal to 0 for each of the three data points. Because for this data-set, when x is 1, then y is 1. When w is also 1, then f(x) equals 1, so f(x) equals y for this first training example, and the difference is 0. Plugging this into the cost function J, you get 0 squared. Similarly, when x is 2, then y is 2, and f(x) is also 2. Again, f(x) equals y, for the second training example. In the cost function, the squared error for the second example is also 0 squared. Finally, when x is 3, then y is 3 and f(3) is also 3. In a cost function the third squared error term is also 0 squared.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/Ñost_function_params_optimization.png\" width=\"500\"/>\n",
    "<br>\n",
    "\n",
    "Visually you can see that the error or difference is equal to the height of this vertical line here when x is equal to 1. Because this lower line is the gap between the actual value of y and the value that the function f predicted, which is a bit further down here. For this first example, when x is 1, f(x) is 0.5. The squared error on the first example is 0.5 minus 1 squared. Remember the cost function, we'll sum over all the training examples in the training set. Let's go on to the second training example. When x is 2, the model is predicting f(x) is 1 and the actual value of y is 2. The error for the second example is equal to the height of this little line segment here, and the squared error is the square of the length of this line segment, so you get 1 minus 2 squared. Let's do the third example. Repeating this process, the error here, also shown by this line segment, is 1.5 minus 3 squared. Next, we sum up all of these terms, which turns out to be equal to 3.5.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_fun_calc_example.png\" width=\"600\"/>\n",
    "<br>\n",
    "\n",
    "Then we multiply this term by 1 over 2m, where m is the number of training examples. Since there are three training examples m equals 3, so this is equal to 1 over 2 times 3, where this m here is 3. If we work out the math, this turns out to be 3.5 divided by 6. The cost J is about 0.58\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_fun_calc_example_detailed.png\" width=\"600\"/>\n",
    "<br>\n",
    "\n",
    "\n",
    "Given this, how can you choose the value of w that results in the function f, fitting the data well? Well, as you can imagine, choosing a value of w that causes J of w to be as small as possible seems like a good bet. J is the cost function that measures how big the squared errors are, so choosing w that minimizes these squared errors, makes them as small as possible, will give us a good model.\n",
    "\n",
    "<br>\n",
    "<img src=\"../../img/coursera/supervised/lr/cost_fun_current_example_j_w.png\" width=\"300\"/>\n",
    "<br>\n",
    "\n",
    "In this example, if you were to choose the value of w that results in the smallest possible value of J of w you'd end up picking w equals 1. As you can see, that's actually a pretty good choice. This results in the line that fits the training data very well.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}