{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### This week, you will learn two key unsupervised learning algorithms: clustering and anomaly detection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clustering\n",
    "\n",
    "A clustering algorithm looks at a number of data points and automatically finds data points that are related or similar to each other."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/supervised_learning_example.png\" width=\"500\"/>\n",
    "\n",
    "With supervised learning, we had a training set with both the input features x as well as the labels y. We could plot a dataset like this and fit, say, a logistic regression algorithm or a neural network to learn a decision boundary like that."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/unsupervised_learning_example.png\" width=\"500\"/>\n",
    "\n",
    "Unsupervised learning, you are given a dataset like this with just x, but not the labels or the target labels y. That's why when I plot a dataset, it looks like this, with just dots rather than two classes denoted by the x's and the o's. Because we don't have target labels y, we're not able to tell the algorithm what is the \"right answer, y\" that we wanted to predict."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-means intuition\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_intuition.png\" width=\"500\"/>\n",
    "\n",
    "Centers of the cluster are called cluster centroids. After it's made an initial guess at where the cluster centroid is, it will go through all of these examples, x(1) through x(30), my 30 data points. And for each of them it will check if it is closer to the red cluster centroid, shown by the red cross, or if it's closer to the blue cluster centroid, shown by the blue cross. And it will assign each of these points to whichever of the cluster centroids It is closer to.\n",
    "\n",
    "Each of these little round dots, either red or blue, depending on whether that example is closer to the red or to the blue cluster centroid.\n",
    "\n",
    "Which is a sign points to clusters centroids. And all that means is it will associate which I'm illustrating with the color, every point of one of the cluster centroids."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_intuition2.png\" width=\"500\"/>\n",
    "\n",
    "The second of the two steps that K-means does is, it'll look at all of the red points and take an average of them. And it will move the red cross to whatever is the average location of the red dots, which turns out to be here. And so the red cross, that is the red cluster centroid will move here. And then we do the same thing for all the blue dots. Look at all the blue dots, and take an average of them, and move the blue cross over there. So you now have a new location for the blue cluster centroid as well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_intuition3.png\" width=\"500\"/>\n",
    "\n",
    "Next, Repeat **Step 1 and Step 2** change color of the dots and move centroids to the new, better location.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_intuition4.png\" width=\"500\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-means algorithm in details\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_algo.png\" width=\"500\"/>\n",
    "\n",
    "Algo is simple, first - assign points to cluster centroinds (red and blue). Second - move cluster centroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_not_well_separated.png\" width=\"500\"/>\n",
    "\n",
    "If you're trying to decide exactly how to size your small, medium, and large t-shirts, you might then choose the dimensions of your small t-shirt to try to make it fit these individuals well. The medium-size t-shirt to try to fit these individuals well, and the large t-shirt to try to fit these individuals well with potentially the cluster centroids giving you a sense of what is the most representative height and weight that you will want your three t-shirt sizes to fit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K-means optimization objective\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_optimization_obj.png\" width=\"500\"/>\n",
    "\n",
    "The cluster centroid to which extent has been assigned and taking the square of that distance and that would be one of the terms over here that we're averaging over. And it turns out that what the K means album is doing is trying to find assignments of points of clusters centroid as well as find locations of clusters centroid that minimizes the squared distance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/measure_square_err.png\" width=\"500\"/>\n",
    "\n",
    "Visually if you were to computer it would be to look at everyone at the blue points and measure these distances and computer square. And then also similarly look at every one of the red points and compute these distances and compute the square.\n",
    "\n",
    "And then the average of the squares of all of these differences for the red and the blue points is the value of the cost function J, at this particular configuration of the parameters for kings. **And what they will do on every step is try to update the cluster**\n",
    "\n",
    " By the way, this cost function J also has a name in the literature is called the **distortion function.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/cost_fun_for_k_means.png\" width=\"500\"/>\n",
    "\n",
    "And if you were to sign it too close to central to then this square distance would be the square of this much smaller distance. So if you want to minimize this term, you will take X I and assign it to the closer centroid, which is exactly what the album is doing up here. So that's why the step where you sign points to cluster century is choosing the values for CI to try to minimize J. Without changing, we went through the UK for now, but just choosing the values of C1 through CM to try to make these terms as small as possible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/moving_centroids.png\" width=\"500\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing K-means\n",
    "\n",
    "In order to choose the cluster centroids, the most common way is to randomly pick K training examples:\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/random_initialization.png\" width=\"500\"/>\n",
    "\n",
    "Then we would set new one through mu K equal to these K training examples. So I might initialize my red cluster centroid here, and initialize my blue cluster sent troy over here, in the example where K was equal to two.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/random_init_pseudocode.png\" width=\"500\"/>\n",
    "\n",
    "So if you want to give k means multiple shots at finding the best local optimum. If you want to try multiple random initialization, so give it a better chance of finding this good clustering up on top. One other thing you could do with the kings algorithm is to run it multiple times and then to try to find the best local optima."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initializing K-means\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/k_means_steps1.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "When running K means you should pretty much always choose the number of cluster central's K to be lessened to training examples m.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/centroid_random_init.png\" width=\"500\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/centroid_random_init2.png\" width=\"500\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choosing the number of clusters\n",
    "\n",
    "How do you decide how many clusters to used. Do you want two clusters or three clusters of five clusters or 10 clusters? Let's take a look.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/choosing_val_of_k.png\" width=\"500\"/>\n",
    "\n",
    "One thing you could do is run K-means on this data set to find the clusters, in which case you may find clusters like that and this would be how you size your **small, medium, and large** t-shirts, but how many t-shirt sizes should there be? Well, it's ambiguous.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/choosing_val_of_k2.png\" width=\"500\"/>\n",
    "\n",
    "look at these two solutions to see based on the trade-off between fits of t-shirts with more sizes, results in better fit versus the extra cost of making more t-shirts where making fewer t-shirts is simpler and less expensive to try to decide what makes sense for the t-shirt business."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/q1.png\" width=\"800\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/q2.png\" width=\"800\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/q3.png\" width=\"800\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/q4.png\" width=\"800\"/>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Anomaly detection\n",
    "\n",
    "**Notice that this is still primarily an unsupervised learning algorithm because the training sets really has no labels or they all have labels that we're assuming to be y equals 0 and so we learned from the training set**\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_1.png\" width=\"500\"/>\n",
    "\n",
    "Finding unusual events. Here's the idea, after an aircraft engine rolls off the assembly line, you can compute a number of different features of the aircraft engine. So, say feature x1 measures the heat generated by the engine. Feature x2 measures the vibration intensity and so on and so forth for additional features as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_2.png\" width=\"700\"/>\n",
    "\n",
    "If a brand new aircraft engine were to roll off the assembly line and it had a new feature vector given by Xtest, we'd like to know does this engine look similar to ones that have been manufactured before? So is this probably okay? Or is there something really weird about this engine which might cause this performance to be suspect, meaning that maybe we should inspect it even more carefully before we let it get shipped out and be installed in an airplane and then hopefully nothing will go wrong with it. Here's how an anomaly detection algorithm works."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_3.png\" width=\"700\"/>\n",
    "\n",
    "But if this new aircraft engine has a heat and vibration signature that is say all the way down here, then this data point down here looks very different than once we saw up on top. And so we will probably say, boy, this looks like an anomaly. This doesn't look like the examples I've seen before, we better inspect this more carefully before we let this engine get installed on an airplane."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### A density estimation technique\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/density_estimation.png\" width=\"700\"/>\n",
    "\n",
    " what that means is, when you're given your training sets of these m examples, the first thing you do is build a model for the probability of x. In other words, the learning algorithm will try to figure out what are the values of the features x1 and x2 that have **high probability** and what are the values that are less likely or have a lower chance or **lower probability** of being seen in the data set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/density_estimation2.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gaussian (normal) distribution\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gausian_normal_distribution.png\" width=\"700\"/>\n",
    "\n",
    "What that means is that the probability of x looks like a curve that goes like this. The center or the middle of the curve is given by the mean Mu, and the standard deviation or the width of this curve is given by that variance parameter Sigma. Technically, Sigma is called the standard deviation and the square of Sigma or Sigma squared is called the variance of the distribution.\n",
    "\n",
    "It means that if you were to get, say, 100 numbers drawn from this probability distribution, and you were to plot a histogram of these 100 numbers drawn from this distribution, you might get a histogram that looks like this. It looks vaguely bell-shaped. What this curve on the left indicates is not if you have just 100 examples or 1,000 or a million or a billion. But if you had a practically infinite number of examples, and you were to draw a histogram of this practically infinite number of examples with a very fine histogram bin. Then you end up with essentially this bell-shaped curve here on the left."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gausian_normal_distribution2.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gausian_normal_distribution3.png\" width=\"700\"/>\n",
    "\n",
    "This now creates a much wider distribution because Sigma here is now much larger, and because it's now a wider distribution is become shorter as well because the area under the curve is still equals 1. Finally, let's try changing the mean parameter Mu, and I'll leave Sigma equals 0.5. In this case, the center of the distribution Mu moves over here to the right. But the width of the distribution is the same as the one on top because the standard deviation is 0.5 in both of these cases on the right."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The first step is to create the Gaussian distribution model. In this case, we will use **mu (μ)** equal to 2 and **sigma (σ)** equal to 1. **μ represents the mean value, and σ represents where 68% of the data is located**. Using 2 σ will provide where 95% of the data is located. Sigma (σ) is measured from the mean (μ) and represents how far or close data is respect to the mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gausian_dist1.png\" width=\"700\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gausian_dist2.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While plotting the data points we can see how they are concentrated around μ and that most of the data (68%) is contained within **μ-σ and μ+σ. (2 - 1 and 2 + 1)**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A probability distribution is a statistical function that describes the likelihood of obtaining the possible values that a random variable can take. By this, we mean the range of values that a parameter can take when we **randomly pick up values from it.** A probability distribution can be discrete or continuous.\n",
    "<br>\n",
    "\n",
    "##### Example:\n",
    "If we were asked to pick up 1 adult randomly and asked what his/her (assuming gender does not affect height) height would be? There’s no way to know what the height will be. But if we have the distribution of heights of adults in the city, we can bet on the most probable outcome.\n",
    "\n",
    "\n",
    "A Normal Distribution is also known as a Gaussian distribution or famously Bell Curve. People use both words interchangeably, but it means the same thing. It is a continuous probability distribution.\n",
    "\n",
    "The probability density function for Normal Distribution:\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/normal_dist_formula.png\" width=\"700\"/>\n",
    "**where, μ = Mean , σ = Standard deviation , x = input value.**\n",
    "\n",
    "**Mean** – The mean is the usual average. The sum of total points divided by the total number of points.\n",
    "**Standard Deviation** – Standard deviation tells us how “spread out” the data is. It is a measure of how far each observed value is from the mean.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Probability Density')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating a series of data of in range of 1-50.\n",
    "x = np.linspace(1, 50, 200)\n",
    "\n",
    "\n",
    "#Creating a Function. based on (normal distribution) formula\n",
    "def normal_dist(x, mean, sd):\n",
    "    prob_density = (np.pi * sd) * np.exp(-0.5 * ((x - mean) / sd) ** 2)\n",
    "    return prob_density\n",
    "\n",
    "\n",
    "#Calculate mean and Standard deviation.\n",
    "mean = np.mean(x)\n",
    "sd = np.std(x)\n",
    "\n",
    "#Apply function to the data.\n",
    "pdf = normal_dist(x, mean, sd)\n",
    "\n",
    "#Plotting the Results\n",
    "plt.plot(x, pdf, color='red')\n",
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Probability Density')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/normal_distribution_parameters.png\" width=\"700\"/>\n",
    "\n",
    "When you're applying this to anomaly detection, here's what you have to do. You are given a dataset of m examples, and here x is just a number. Here, are plots of the training sets with 11 examples. What we have to do is try to estimate what a good choice is for the mean parameter Mu, as well as for the variance parameter Sigma squared. Given a dataset like this, it would seem that a Gaussian distribution maybe looking like that with a center here and a standard deviation like that. This might be a pretty good fit to the data. The way you would compute Mu and Sigma squared mathematically is our estimate for Mu will be just the average of all the training examples. It's 1 over m times sum from i equals 1 through m of the values of your training examples. The value we will use to estimate Sigma squared will be the average of the squared difference between two examples, and that Mu that you just estimated here on the left.\n",
    "\n",
    "It turns out that if you implement these two formulas encodes with this value for Mu and this value for Sigma squared, then you pretty much get the Gaussian distribution that I hand drew on top. This will give you a choice of Mu and Sigma for a Gaussian distribution so that it looks like the 11 training samples might have been drawn from this Gaussian distribution. If you've taken an advanced statistics class, you may have heard that these formulas for Mu and Sigma squared are technically called the maximum likelihood estimates for Mu and Sigma. Some statistics classes will tell you to use the formula 1 over n minus 1 instead of 1 over m. In practice, using 1 over m or 1 over n minus 1 makes very little difference. I always use 1 over m, but just some other properties of dividing by m minus 1 that some statisticians prefer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/density_estimation_01.png\" width=\"700\"/>\n",
    "\n",
    "Now, to fill in this equation a little bit more, we are saying that the probability of all the features of this vector features x, is the product of p(x) 1 and p(x2) and so on up through p(xn). And in order to model the probability of x1, say the heat feature in this example we're going to have two parameters, new 1 and sigma 1 or sigma squared is 1. And what that means is we're going to estimate, the mean of the feature x1 and also the variance of feature x1 and that will be new 1 and sigma 1. To model p(x2) x2 is a totally different feature measuring the vibrations of the airplane engine. We're going to have two different parameters, which I'm going to write as mu 2, sigma 2 squared.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/density_estimation_02.png\" width=\"700\"/>\n",
    "\n",
    "And it turns out this will correspond to the mean or the average of the vibration feature and the variance of the vibration feature and so on. If you have additional features mu 3 sigma 3 squared up through mu n and sigma n squared. In case you're wondering why we multiply probabilities, maybe here's 1 example that could build intuition. Suppose for an aircraft engine there's a 1/10 chance that it is really hot, unusually hot and maybe there is a 1 in 20 chance that it vibrates really hard. Then, what is the chance that it runs really hot and vibrates really hard. We're saying that the chance of that is **1/10 times 1/20 which is 1/200. So it's really unlikely to get an engine that both fronts really hot and vibrates really hard.** It's the **product of these two probabilities A somewhat more compact way to write this equation up here**\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/density_estimation_03.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_04.png\" width=\"700\"/>\n",
    "\n",
    "\n",
    "And if you substitute in, the formula for this probability, you end up with this expression 1 over root 2 pi sigma j of e to this expression over here. And so xj are the features, this is a j feature of your new example, mu j and sigma j are numbers or parameters you have computed in the previous step. And if you compute out this formula, you get some number for p(x). **And the final step is to see a p(x) is less than epsilon. And if it is then you flag that it is an anomaly.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_05.png\" width=\"700\"/>\n",
    "\n",
    "if even 1 of the features of the new example was way out here, say, then P f xJ would be very small. And if just 1 of the terms in this product is very small, then this overall product, when you multiply together will tend to be very small and does p(x) will be small. And what anomaly detection is doing into the algorithm is a systematic way of quantifying whether or not this new example x has any features that are unusually large or unusually small. Now, let's take a look at what all this actually means on 1 example, Here's the data set with features x 1 and x 2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_example.png\" width=\"700\"/>\n",
    "\n",
    "If you were to compute the meme of the Features x 1, you end up with five, which is why you want is equal to 1. And it turns out that for this data said, if you compute sigma 1, it will be equal to about 2. And if you were to compute mu to the average of the features on next to the average is three and similarly is variance or standard deviation is much smaller, which is why Sigma 2 is equal to 1. So that corresponds to this Gaussian distribution for x 1 and this Gaussian distribution for x 2. I"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_detection_example2.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So you've seen the process of how to build an anomaly detection system. But how do you choose the parameter epsilon? And how do you know if your anomaly detection system is working well\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/algo_evaluation.png\" width=\"700\"/>\n",
    "\n",
    "Now, let's take a closer look at how to actually evaluate the algorithm on your cross-validation sets or on the test set. Here's what you'd do.\n",
    "\n",
    "- You would first fit the model p of x on the training set. This was a 6,000 examples of goods engines.\n",
    "- Then on any cross validation or test example x, you would compute p of x and you will predict y equals 1.\n",
    "- That is anomalous if p of x is less than Epsilon and you predict y is 0, if p of x is greater than or equal to Epsilon. Based on this, you can now look at how accurately this algorithm's predictions on the cross validation or test set matches the labels, y you have in the cross validation or the test sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Anomaly detection vs. supervised learning\n",
    "\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_vs_supervised_01.png\" width=\"700\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_vs_supervised_02.png\" width=\"700\"/>\n",
    "\n",
    "Framework for deciding when you have a small set of positive examples as well as maybe a large set of negative examples. Whether to use anomaly detection or supervised learning. Anomaly detection tries to find brand new positive examples that may be unlike anything you've seen before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Choosing what features to use\n",
    "How to tune the features for anomaly detection, to try to get you the best possible performance.\n",
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gaussian_good_candidate.png\" width=\"500\"/>\n",
    "\n",
    "This distribution here looks pretty Gaussian. So this would be a good candidate feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gaussian_good_candidate_1.png\" width=\"500\"/>\n",
    "\n",
    "This does not at all look like that symmetric bell shaped curve. When that is the case, I would consider if you can take this feature X, and transform it in order to make a more Gaussian. For example, maybe if you were to compute the log of X and plot a hissed a gram of log of X, look like this, and this looks much more Gaussian. And so if this feature was feature X one, then instead of using the original feature X one which looks like this on the left, you might instead replace that feature with log of X one, to get this distribution over here. Because when X one is made more Gaussian. When anomaly detection models P of X one using a Gaussian distribution like that, is more likely to be a good fit to the data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/gaussian_good_candidate_2.png\" width=\"500\"/>\n",
    "\n",
    "So when I'm building an anomaly detection system, I'll sometimes take a look at my features, and if I see any highly non Gaussian by plotting hissed a gram, I might choose transformations like these or others, In order to try to make it more Gaussian."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/error_analysis_anomaly.png\" width=\"700\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/error_analysis_anomaly_2.png\" width=\"700\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_q0.png\" width=\"900\"/>\n",
    "<br>\n",
    "<img src=\"../../../img/3_unsupervised_learning_recommenders_reinforcement_learning/week1/anomaly_q1.png\" width=\"900\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}