{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost function for the NN\n",
    "1. Learning algorithm for fitting the parameters of a neural network given a training set.\n",
    "\n",
    "#### Backpropagation Algorithm\n",
    "\"Backpropagation\" is neural-network terminology for minimizing our cost function, just like what we were doing with gradient descent in logistic and linear regression. We want to minimize our cost function J using an optimal set of parameters in 'theta'.\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/nn/numerical_estimate_gradient.png\" width=\"500\"/>\n",
    "\n",
    "#### Random Initialization of 'theta'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Combine all peaces togather, implement a neural network learning algorithm\n",
    "1. Pick some network architecture and by architecture I just mean connectivity pattern between the neurons.\n",
    "2. Choices of how many hidden units in each layer and how many hidden layers, those are architecture choices. For example with three input units and five hidden units and four output units versus one of 3, 5 hidden, etc...\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/nn/connectivety_pattern.png\" width=\"500\"/>\n",
    "\n",
    "#### How to choose network architecture\n",
    "1. First, the number of input units well that's pretty well defined. And once you decides on the fix set of features x the number of input units will just be, you know, the dimension of your features x(i) would be determined by that.\n",
    "2. If you are doing multiclass classifications the number of output of this will be determined by the number of classes in your classification problem. And just a reminder if you have a multiclass classification where y takes on say values between.\n",
    "3. If you have a multiclass classification where y takes on say values between 1 and 10 you have 10 possible classes.\n",
    "4. Number of hidden units and the number of hidden layers, a reasonable default is to use a single hidden layer and so this type of neural network shown on the left with just one hidden layer is probably the most common.\n",
    "5. Usually the number of hidden units in each layer will be maybe comparable to the dimension of x, comparable to the number of features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6 steps what we need to implement in order to trade in neural network\n",
    "\n",
    "1. Set up the neural network and to randomly initialize the values of the weights. And we usually initialize the weights to small values near zero.\n",
    "2. Implement forward propagation so that we can input any excellent neural network and compute h of x which is this output vector of the y values.\n",
    "3. Implement code to compute this cost function j of theta.\n",
    "4. Implement back-prop, or the back-propagation algorithm, to compute these partial derivatives terms, partial derivatives of j of theta with respect to the parameters.\n",
    "5. use gradient checking to compare these partial derivative terms that were computed. So, I've compared the versions computed using back propagation versus the partial derivatives computed using the numerical estimates as using numerical estimates of the derivatives. So, I do gradient checking to make sure that both of these give you very similar values.\n",
    "6. Use an optimization algorithm such as gradient descent, or one of the advanced optimization methods such as LB of GS, contract gradient has embodied into fminunc or other optimization methods. (optimization methods to try to minimize j of theta as a function of the parameters theta)\n",
    "\n",
    "///!!! CODE HERE !!!\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How to improve a Learning Algorithm and improve the selected model\n",
    "\n",
    "1. Get more training examples\n",
    "2. Reduce amount of features by \"feature importance\"\n",
    "3. Try getting additional features (collect more data and use like additional features)\n",
    "4. Try adding polynomial features (x1^2, x2^2, x1, x2, etc)\n",
    "5. Decreasing regularization parameter (lambda)\n",
    "6. Increasing regularization parameter (lambda)\n",
    "\n",
    "\n",
    "\n",
    "### Evaluating hypothesis\n",
    "To evaluate a hypothesis, given a dataset of training examples, we can split up the data into two sets: a training set and a test set. Typically, the training set consists of 70 % of your data and the test set is the remaining 30 %.\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/test_set_error_calculation.png\" width=\"900\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Selection and Train/Cross Validation/Test Sets\n",
    "\n",
    "Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data.\n",
    "1. Use cross-validation to detect overfitting, ie, failing to generalize a pattern.\n",
    "\n",
    "\n",
    "Just because a learning algorithm fits a training set well, that does not mean it is a good hypothesis. It could over fit and as a result your predictions on the test set would be poor.\n",
    "\n",
    "### Improve the performance of the learning algorithm (Bias \"underfit\" vs Variance \"overfit\")\n",
    "\n",
    "1. High bias (underfit) - high error\n",
    "2. Variance (overfiting) - very low error\n",
    "\n",
    "<img src=\"../img/evaluate_learning/bias_variance.png\" width=\"900\"/>\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/combinations_train_cros_val.png\" width=\"900\"/>\n",
    "\n",
    "1. We need to distinguish whether bias or variance is the problem contributing to bad predictions.\n",
    "2. High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.\n",
    "\n",
    "<img src=\"../img/evaluate_learning/bias_variance_diagnostic.png\" width=\"900\"/>\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Learning curves\n",
    "Training an algorithm on a very few number of data points (such as 1, 2 or 3) will easily have 0 errors because we can always find a quadratic curve that touches exactly those number of points.\n",
    "\n",
    "\n",
    "### Our decision process can be broken down as follows:\n",
    "1. Getting more training examples: Fixes high variance\n",
    "2. Trying smaller sets of features: Fixes high variance\n",
    "3. Adding features: Fixes high bias\n",
    "4. Adding polynomial features: Fixes high bias\n",
    "5. Decreasing λ: Fixes high bias\n",
    "6. Increasing λ: Fixes high variance.\n",
    "\n",
    "\n",
    "### Diagnosing Neural Networks\n",
    "1. A neural network with ***fewer parameters*** is prone to ***underfitting***. It is also computationally cheaper.\n",
    "2. A large neural network with ***more parameters*** is prone to ***overfitting***. It is also computationally expensive. In this case you can use regularization (increase λ) to address the overfitting.\n",
    "\n",
    "Using a single hidden layer is a good starting default. You can train your neural network on a number of hidden layers using your cross validation set. You can then select the one that performs best.\n",
    "\n",
    "\n",
    "### Model Complexity Effects\n",
    "\n",
    "### Train/Test/CV error calculation\n",
    "\n",
    "<img src=\"../img/evaluate_learning/train_test_valid_err.png\" width=\"900\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/high_bias.png\" width=\"900\"/>\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/high_variance.png\" width=\"900\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Questions:\n",
    "0. You train a learning algorithm, and find that it has unacceptably high error on the test set.  You plot the learning curve, and obtain the figure below.  Is the algorithm suffering from high bias, high variance, or neither?\n",
    "\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/high_bias_suffering.png\" width=\"300\"/>\n",
    "<br>\n",
    "\n",
    "-  High bias\n",
    "\n",
    "\n",
    "1. In which of the following circumstances is getting more training data likely to significantly help a learning algorithm’s performance?\n",
    "- Algorithm is suffering from high variance.\n",
    "- (cross validation error) is much larger than J(train)\n",
    "\n",
    "2. You train a learning algorithm, and find that it has unacceptably high error on the test set.  You plot the learning curve, and obtain the figure below.  Is the algorithm suffering from high bias, high variance, or neither?\n",
    "<br>\n",
    "<img src=\"../img/evaluate_learning/question_metrics_suffering.png\" width=\"300\"/>\n",
    "<br>\n",
    "\n",
    "-  High variance\n",
    "\n",
    "\n",
    "\n",
    "3. Suppose you have implemented regularized logistic regression to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large errors with its predictions on the new images.  However, your hypothesis performs well (has low error) on the training set. Which of the following are promising steps to take? Check all that apply.\n",
    "\n",
    "NOTE: Since the hypothesis performs well (has low error) on the training set, it is suffering from high variance (overfitting)\n",
    "\n",
    "- Try increasing the regularization parameter λ.\n",
    "- Try using a smaller set of features.\n",
    "- Get more training examples.\n",
    "\n",
    "\"The gap in errors between training and test suggests a high variance problem in which the algorithm has overfit the training set. Increasing the regularization parameter will reduce overfitting and help with the variance problem.\"\n",
    "\n",
    "\n",
    "4. Suppose you have implemented regularized logistic regression to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis performs **poorly** on the training set. Which of the following might be promising steps to take? Check all that apply.\n",
    "\n",
    "NOTE: Since the hypothesis performs poorly on the training set, it is suffering from high bias (underfitting)\n",
    "\n",
    "- Try decreasing the regularization parameter λ.\n",
    "- Try adding polynomial features.\n",
    "- Try to obtain and use additional features.\n",
    "\"The poor performance on both the training and test sets suggests a high bias problem. Adding more complex features will increase the complexity of the hypothesis, thereby improving the fit to both the train and test data.\"\n",
    "\n",
    "\n",
    "\n",
    "???  regularization parameter λ - Regularization parameter will reduce overfitting and help with the variance problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ML system design\n",
    "\n",
    "### Supervised learning example spam/not spam\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}